<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>chpengzh&#39;s blog</title>
  
  <subtitle>谦逊，自律，不留余力</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://chpengzh.github.io/"/>
  <updated>2019-11-25T14:28:24.814Z</updated>
  <id>https://chpengzh.github.io/</id>
  
  <author>
    <name>chpengzh</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>JDK 线程池定义</title>
    <link href="https://chpengzh.github.io/JDK-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9A%E4%B9%89/"/>
    <id>https://chpengzh.github.io/JDK-%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%AE%9A%E4%B9%89/</id>
    <published>2019-11-25T14:27:53.000Z</published>
    <updated>2019-11-25T14:28:24.814Z</updated>
    
    <content type="html"><![CDATA[<p>使用一个或多个池化线程来执行任务的<code>ExecutorService</code>, 通常情况下使用<code>Executors</code>类提供的工厂方法进行配置和创建。</p><blockquote><p>An ExecutorService that executes each submitted task using one of possibly several pooled threads, normally configured using Executors factory methods.</p></blockquote><p>线程池涉及到了两个不同的问题点: 人们常常使用大量的异步任务，通过最终归并每个任务的执行结果的方式去提升执行任务的性能。这种方式需要使用到一些有限且十分宝贵的资源，并对其进行管理。它们包括线程，被消费任务的集合；有的线程池还包含一些基本的统计项，比如已完成任务的数量等。</p><blockquote><p>Thread pools address two different problems: they usually provide improved performance when executing large numbers of asynchronous tasks, due to reduced per-task invocation overhead, and they provide a means of bounding and managing the resources, including threads, consumed when executing a collection of tasks. Each ThreadPoolExecutor also maintains some basic statistics, such as the number of completed tasks.</p></blockquote><p>为了更广泛的适用于各个场景，这个类提供了非常多的参数和拓展接口。虽然程序员们通常更习惯于去使用<code>Executors</code>提供的一些更简单的工厂方法:<code>Executors.newCachedThreadPool</code>(无界线程池，提供了自动扩容线程机制)，<code>Executors.newFixedThreadPool</code>(限定大小线程池)，<br><code>Executors.newSingleThreadExecutor</code>(单线程异步任务线程池)。这些方法提供了大多数应用场景下的线程池初始化配置方案。其他场景下，可以使用以下配置方法定制该类:</p><blockquote><p>To be useful across a wide range of contexts, this class provides many adjustable parameters and extensibility hooks. However, programmers are urged to use the more convenient Executors factory methods Executors.newCachedThreadPool (unbounded thread pool, with automatic thread reclamation), Executors.newFixedThreadPool (fixed size thread pool) and Executors.newSingleThreadExecutor (single background thread), that preconfigure settings for the most common usage scenarios. Otherwise, use the following guide when manually configuring and tuning this class:</p></blockquote><h2 id="1-核心线程数-Core-和最大线程数-Maxium"><a href="#1-核心线程数-Core-和最大线程数-Maxium" class="headerlink" title="1. 核心线程数(Core)和最大线程数(Maxium)"></a>1. 核心线程数(Core)和最大线程数(Maxium)</h2><p>线程池对象会通过核心线程数和最大线程数配置规则，自动扩容线程数量。当提交执行一个新的任务时，如果当前线程总数少于核心线程数，线程池会创建一个新的线程来执行这个任务，哪怕当前有线程正处于空闲(idle)状态。如果当前有超过核心线程数，但少于最大线程数的线程处于运行(Running)状态，当且仅当队列满时才会扩容线程。如果设置最大线程数和核心线程数为同一个值，你能够创建一个固定大小(fixed-size)的线程池。如果设置最大线程数为一个无界值(例如<code>Integer.MAX_VALUE</code>)，你就能够创建一个能同时执行任意并发数任务的线程池。通常情况下，核心线程数和最大线程数仅是在构造时候就进行了设置，但是他们也可以在创建后通过set方法进行动态地修改.</p><blockquote><p><strong>Core and maximum pool sizes</strong><br>A ThreadPoolExecutor will automatically adjust the pool size (see getPoolSize) according to the bounds set by corePoolSize (see getCorePoolSize) and maximumPoolSize (see getMaximumPoolSize). When a new task is submitted in method execute(Runnable), and fewer than corePoolSize threads are running, a new thread is created to handle the request, even if other worker threads are idle. If there are more than corePoolSize but less than maximumPoolSize threads running, a new thread will be created only if the queue is full. By setting corePoolSize and maximumPoolSize the same, you create a fixed-size thread pool. By setting maximumPoolSize to an essentially unbounded value such as Integer.MAX_VALUE, you allow the pool to accommodate an arbitrary number of concurrent tasks. Most typically, core and maximum pool sizes are set only upon construction, but they may also be changed dynamically using setCorePoolSize and setMaximumPoolSize.</p></blockquote><h2 id="2-按需构造"><a href="#2-按需构造" class="headerlink" title="2. 按需构造"></a>2. 按需构造</h2><p>通常情况下，核心线程只会在新任务到来之际才进行初始化创建，但是我们可以通过使用方法<code>prestartCoreThread</code>或<code>prestartAllCoreThreads</code>来强制核心线程进行初始化。在使用一个非空的任务队列构造线程池的时候，你通常会需要先启动池中的核心线程。</p><blockquote><p><strong>On-demand construction</strong><br>By default, even core threads are initially created and started only when new tasks arrive, but this can be overridden dynamically using method prestartCoreThread or prestartAllCoreThreads. You probably want to prestart threads if you construct the pool with a non-empty queue.</p></blockquote><h2 id="3-创建新线程"><a href="#3-创建新线程" class="headerlink" title="3. 创建新线程"></a>3. 创建新线程</h2><p>新线程允许通过<code>ThreadFactory</code>来创建。如果不指定，则会使用默认的方法<code>Executors.defaultThreadFactory</code>来进行创建；在这种情况下所有线程均在一个<code>ThreadGroup</code>下，拥有<code>NORM_PRIORITY</code>的执行权重，且非守护线程状态。通过提供一个不同的<code>ThreadFactory</code>，你将可以定制现成的组，执行权重以及守护进程状态等等属性。如果<code>ThreadFactory</code>在调用过程中创建线程失败并返回了null，任务提交会成功返回，但是可能无法执行任何任务。所有线程必须具有<code>modifyThread</code>的运行时权限。如果工作线程或调用线程不具备该权限，服务会被降级: 被修改的配置可能不会及时地生效，并且一个关闭状态的线程池，会在任务执行完毕后依然处于无法关闭的状态。</p><blockquote><p><strong>Creating new threads</strong><br>New threads are created using a ThreadFactory. If not otherwise specified, a Executors.defaultThreadFactory is used, that creates threads to all be in the same ThreadGroup and with the same NORM_PRIORITY priority and non-daemon status. By supplying a different ThreadFactory, you can alter the thread’s name, thread group, priority, daemon status, etc. If a ThreadFactory fails to create a thread when asked by returning null from newThread, the executor will continue, but might not be able to execute any tasks. Threads should possess the “modifyThread” RuntimePermission. If worker threads or other threads using the pool do not possess this permission, service may be degraded: configuration changes may not take effect in a timely manner, and a shutdown pool may remain in a state in which termination is possible but not completed.</p></blockquote><h2 id="4-保活时间"><a href="#4-保活时间" class="headerlink" title="4. 保活时间"></a>4. 保活时间</h2><p>如果当前池线程数超过了核心线程数大小，超过部分线程如果最长保活时间(keepAliveTime)仍然处于休眠(idle)状态，则线程资源会被回收。这个特性旨在当处于线程将不再被使用状态的场景下，能有效降低消耗的资源。通常情况下，保活时间策略只会在当线程数超过核心线程数时才会生效。但是如果调用了方法<code>allowCoreThreadTimeOut(boolean)</code>，只要保活时间为一个正数，则可以对核心线程也能激活这个保活策略。</p><blockquote><p><strong>Keep-alive times</strong><br>If the pool currently has more than corePoolSize threads, excess threads will be terminated if they have been idle for more than the keepAliveTime (see getKeepAliveTime(TimeUnit)). This provides a means of reducing resource consumption when the pool is not being actively used. If the pool becomes more active later, new threads will be constructed. This parameter can also be changed dynamically using method setKeepAliveTime(long, TimeUnit). Using a value of Long.MAX_VALUE TimeUnit.NANOSECONDS effectively disables idle threads from ever terminating prior to shut down. By default, the keep-alive policy applies only when there are more than corePoolSize threads. But method allowCoreThreadTimeOut(boolean) can be used to apply this time-out policy to core threads as well, so long as the keepAliveTime value is non-zero.</p></blockquote><h2 id="5-队列"><a href="#5-队列" class="headerlink" title="5. 队列"></a>5. 队列</h2><p>任何一个<code>BlockingQueue</code>都可以被用来承载提交和待消费的任务。对队列的使用会对队列大小敏感:如果当前运行线程少于核心线程数，线程池总是会倾向于添加一个线程而不是入队。如果超过了核心线程数，线程池总是会倾向于入队而不是创建线程。如果一个任务无法入队(队列已满并被拒绝入队)这时才会继续创建线程。这里有三类常用的入队策略:</p><ul><li><p><strong>直接阻断提交</strong><br>略</p></li><li><p><strong>无界队列</strong><br>使用无界队列(比如不设置容量的<code>LinkedBlockingQueue</code>)时，如果核心线程全部处于忙碌状态，则新任务将全部入队等待消费。在这种情况下，出核心线程以外不会创建任何额外的线程。(最大线程数在这种场景下不会有任何效果。)这种场景适用于当每个任务都是独立与其他任务执行的时候，所以任务与任务的执行状态不会产生任何相互影响，比如一个应用页面服务器。这种类型的如对策略适用于平滑处理大量短暂而连续的请求，在这种场景下默认在任务的无限制增长过程中，其处理速度最终是快于生产速度的。</p></li><li><p><strong>有界队列</strong><br>一个有界队列(比如<code>ArrayBlockingQueue</code>)会帮助线程池避免耗尽最大线程数的线程资源，但是会导致调节控制过程变得更为复杂。队列大小和最大线程池可能会产生相互影响: 使容量大的队列和比较小的线程数可以降低CPU占用，系统资源以及线程上下文切换的损耗，但是理论上会导致性能低下。如果任务总是处于阻塞状态(比如IO等待)，系统就能分配更多的CPU时间给其他线程。使用较小的队列大小自然而然地需要更大的线程数，这样会导致CPU进入忙碌状态，但是同样会增加上下文切换的调度开销，这样也是不可取的做法。</p></li></ul><blockquote><p><strong>Queuing</strong><br>Any BlockingQueue may be used to transfer and hold submitted tasks. The use of this queue interacts with pool sizing:<br>If fewer than corePoolSize threads are running, the Executor always prefers adding a new thread rather than queuing.<br>If corePoolSize or more threads are running, the Executor always prefers queuing a request rather than adding a new thread.<br>If a request cannot be queued, a new thread is created unless this would exceed maximumPoolSize, in which case, the task will be rejected.<br>There are three general strategies for queuing:</p><ul><li><strong>Direct handoffs</strong> </li></ul><p>A good default choice for a work queue is a SynchronousQueue that hands off tasks to threads without otherwise holding them. Here, an attempt to queue a task will fail if no threads are immediately available to run it, so a new thread will be constructed. This policy avoids lockups when handling sets of requests that might have internal dependencies. Direct handoffs generally require unbounded maximumPoolSizes to avoid rejection of new submitted tasks. This in turn admits the possibility of unbounded thread growth when commands continue to arrive on average faster than they can be processed.</p><ul><li><strong>Unbounded queues</strong></li></ul><p>Using an unbounded queue (for example a LinkedBlockingQueue without a predefined capacity) will cause new tasks to wait in the queue when all corePoolSize threads are busy. Thus, no more than corePoolSize threads will ever be created. (And the value of the maximumPoolSize therefore doesn’t have any effect.) This may be appropriate when each task is completely independent of others, so tasks cannot affect each others execution; for example, in a web page server. While this style of queuing can be useful in smoothing out transient bursts of requests, it admits the possibility of unbounded work queue growth when commands continue to arrive on average faster than they can be processed.</p><ul><li><strong>Bounded queues</strong></li></ul><p>A bounded queue (for example, an ArrayBlockingQueue) helps prevent resource exhaustion when used with finite maximumPoolSizes, but can be more difficult to tune and control. Queue sizes and maximum pool sizes may be traded off for each other: Using large queues and small pools minimizes CPU usage, OS resources, and context-switching overhead, but can lead to artificially low throughput. If tasks frequently block (for example if they are I/O bound), a system may be able to schedule time for more threads than you otherwise allow. Use of small queues generally requires larger pool sizes, which keeps CPUs busier but may encounter unacceptable scheduling overhead, which also decreases throughput.</p></blockquote><h2 id="6-拒绝策略"><a href="#6-拒绝策略" class="headerlink" title="6. 拒绝策略"></a>6. 拒绝策略</h2><p>当线程池关闭时，新提交的任务会拒绝执行；同样的当任务消耗尽了用户指定的资源大小，无论是最大线程数还是队列大小，让其处于饱和状态，这种情况下任务也会被拒绝执行。无论是两者中任何一种场景，都会调用<code>RejectedExecutionHandler.rejectedExecution(Runnable, ThreadPoolExecutor)</code>方法来作为它拒绝策略。有四种预定义的拒绝策略方案:</p><ul><li><p>默认的<code>ThreadPoolExecutor.AbortPolicy</code>, 会抛出一个运行时异常<code>RejectedExecutionException</code>供用户捕获</p></li><li><p><code>ThreadPoolExecutor.CallerRunsPolicy</code>, 会在当前线程直接执行任务。这样可以简单地反作用于控制逻辑来降低任务的提交速度</p></li><li><p><code>ThreadPoolExecutor.DiscardPolicy</code>, 无法被执行的策略会被直接丢弃掉</p></li><li><p><code>ThreadPoolExecutor.DiscardOldestPolicy</code>, 如果线程池没有被关闭, 队列头的任务会被舍弃掉, 然后再次尝试入队(如果仍然无法入队，则重试)</p></li></ul><p>除此之外我们也可以自定义其他的拒绝策略。在做这件事的时候需要额外注意，拒绝策略需要工作在特定的队列大小或入队策略条件之上。</p><blockquote><p><strong>Rejected tasks</strong><br>New tasks submitted in method execute(Runnable) will be rejected when the Executor has been shut down, and also when the Executor uses finite bounds for both maximum threads and work queue capacity, and is saturated. In either case, the execute method invokes the RejectedExecutionHandler.rejectedExecution(Runnable, ThreadPoolExecutor) method of its RejectedExecutionHandler. Four predefined handler policies are provided:</p><ul><li><p>In the default <code>ThreadPoolExecutor.AbortPolicy</code>, the handler throws a runtime RejectedExecutionException upon rejection.</p></li><li><p>In <code>ThreadPoolExecutor.CallerRunsPolicy</code>, the thread that invokes execute itself runs the task. This provides a simple feedback control mechanism that will slow down the rate that new tasks are submitted.</p></li><li><p>In <code>ThreadPoolExecutor.DiscardPolicy</code>, a task that cannot be executed is simply dropped.</p></li><li><p>In <code>ThreadPoolExecutor.DiscardOldestPolicy</code>, if the executor is not shut down, the task at the head of the work queue is dropped, and then execution is retried (which can fail again, causing this to be repeated.)</p></li></ul><p>It is possible to define and use other kinds of RejectedExecutionHandler classes. Doing so requires some care especially when policies are designed to work only under particular capacity or queuing policies.</p></blockquote><h2 id="7-钩子方法"><a href="#7-钩子方法" class="headerlink" title="7. 钩子方法"></a>7. 钩子方法</h2><p>线程池类提供了一个支持重载的<code>beforeExecute(Thread, Runnable)</code>和<code>afterExecute(Runnable, Throwable)</code>方法，他们分别会在任务开始和结束时调用。这样在执行每个任务的时候，就能更有效的操作执行环境了。比如说，写入一个线程变量，收集统计信息，或者添加一条日志记录。更进一步，当方法调用结束时我们可以指定一个额外的任务，直到线程池关闭。如果钩子方法抛出了异常，原本的工作线程将中断结束。</p><blockquote><p><strong>Hook methods</strong><br>This class provides protected overridable beforeExecute(Thread, Runnable) and afterExecute(Runnable, Throwable) methods that are called before and after execution of each task. These can be used to manipulate the execution environment; for example, reinitializing ThreadLocals, gathering statistics, or adding log entries. Additionally, method terminated can be overridden to perform any special processing that needs to be done once the Executor has fully terminated.<br>If hook or callback methods throw exceptions, internal worker threads may in turn fail and abruptly terminate.</p></blockquote><h2 id="8-队列保护"><a href="#8-队列保护" class="headerlink" title="8. 队列保护"></a>8. 队列保护</h2><p>队列的<code>getQueue()</code>只允许任务消费队列查看或者debugging。任何其他意图的调用将被抛弃。<br><code>remove(Runnable)</code>和<code>purge</code>方法则只支持当大量队列中任务被取消时才允许被调用，以访问队列存储。</p><blockquote><p><strong>Queue maintenance</strong><br>Method getQueue() allows access to the work queue for purposes of monitoring and debugging. Use of this method for any other purpose is strongly discouraged. Two supplied methods, remove(Runnable) and purge are available to assist in storage reclamation when large numbers of queued tasks become cancelled.</p></blockquote><h2 id="9-结束回收"><a href="#9-结束回收" class="headerlink" title="9. 结束回收"></a>9. 结束回收</h2><p>如果一个线程池会被自动关闭，仅当该线程池不再被程序引用，且不再具有工作线程的时候。如果希望即使用户忘记关闭线程池，也想确保该线程池正确回收，那么必须确保工作线程最终会被销毁。为了实现这个，可以设置合适的保活时间，设置核心线程数为0，或者允许核心线程保活超时。</p><blockquote><p><strong>Finalization</strong><br>A pool that is no longer referenced in a program AND has no remaining threads will be shutdown automatically. If you would like to ensure that unreferenced pools are reclaimed even if users forget to call shutdown, then you must arrange that unused threads eventually die, by setting appropriate keep-alive times, using a lower bound of core threads and/or setting allowCoreThreadTimeOut(boolean).</p></blockquote><h2 id="10-拓展样例"><a href="#10-拓展样例" class="headerlink" title="10. 拓展样例"></a>10. 拓展样例</h2><p>大多数拓展类需要重载一个或多个钩子方法。以如下为例，它拓展了一个简单的pause和resume特性</p><blockquote><p><strong>Extension example</strong><br>Most extensions of this class override one or more of the protected hook methods. For example, here is a subclass that adds a simple pause/resume feature:</p></blockquote><pre><code class="java"> class PausableThreadPoolExecutor extends ThreadPoolExecutor {   private boolean isPaused;   private ReentrantLock pauseLock = new ReentrantLock();   private Condition unpaused = pauseLock.newCondition();   public PausableThreadPoolExecutor(...) { super(...); }   protected void beforeExecute(Thread t, Runnable r) {     super.beforeExecute(t, r);     pauseLock.lock();     try {       while (isPaused) unpaused.await();     } catch (InterruptedException ie) {       t.interrupt();     } finally {       pauseLock.unlock();     }   }   public void pause() {     pauseLock.lock();     try {       isPaused = true;     } finally {       pauseLock.unlock();     }   }   public void resume() {     pauseLock.lock();     try {       isPaused = false;       unpaused.signalAll();     } finally {       pauseLock.unlock();     }   } }</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用一个或多个池化线程来执行任务的&lt;code&gt;ExecutorService&lt;/code&gt;, 通常情况下使用&lt;code&gt;Executors&lt;/code&gt;类提供的工厂方法进行配置和创建。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An ExecutorService that 
      
    
    </summary>
    
    
    
      <category term="java" scheme="https://chpengzh.github.io/tags/java/"/>
    
      <category term="projects" scheme="https://chpengzh.github.io/tags/projects/"/>
    
      <category term="thread-pool" scheme="https://chpengzh.github.io/tags/thread-pool/"/>
    
  </entry>
  
  <entry>
    <title>Maven通用工程模板</title>
    <link href="https://chpengzh.github.io/Maven%E9%80%9A%E7%94%A8%E5%B7%A5%E7%A8%8B%E6%A8%A1%E6%9D%BF/"/>
    <id>https://chpengzh.github.io/Maven%E9%80%9A%E7%94%A8%E5%B7%A5%E7%A8%8B%E6%A8%A1%E6%9D%BF/</id>
    <published>2019-11-24T09:54:06.000Z</published>
    <updated>2019-11-25T14:27:26.354Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Maven通用工程模板方案"><a href="#Maven通用工程模板方案" class="headerlink" title="Maven通用工程模板方案"></a>Maven通用工程模板方案</h1><blockquote><p>本文旨在介绍使用<code>maven archetype</code>进行项目模板管理的方案</p></blockquote><p>工作中常常会遇到这么一种情况：一个产品线或工作组内，会创建数十个甚至上百个结构高度相似，各自承担不同业务的应用工程项目。</p><p>比如一个常见的基于<code>spring-boot</code>的应用工程模块结构可能如下</p><pre><code>-root  |- doc         项目文档与阅读资料  |- facade      接口与模型发布包  |- app         实际服务进程代码  |- checkstyle  项目风格检测工具  |- pom.xml     项目依赖配置与版本管理配置</code></pre><p>以如上工程结构为例，<code>pom.xml</code>和<code>checkstyle</code>通常是高度一致的; </p><p>有时我们需要在研发团队要统一一个相对标准的项目构建结构(以及流水线方案), 比起让各个项目负责人在项目伊始复制粘贴的方案，<br>使用<code>archetype jar</code>进行模板项目的管理和创建则更为友好。</p><p><img src="https://raw.githubusercontent.com/my-helloworld/template-springboot/master/doc/archetype-workflow.png" alt="workflow"></p><h2 id="1-archetype概述"><a href="#1-archetype概述" class="headerlink" title="1. archetype概述"></a>1. <code>archetype</code>概述</h2><p>简单地说，<code>archetype</code>是一个maven的模板工具，<code>archetype</code>定义了一组统配模型，用于构建大量同质的项目结构。<br><code>Archetype</code>可以帮助我们去创建一个供其他研发人员使用的<code>maven</code>项目模板，甚至允许我们和依赖包一样，在仓库中对模板进行版本管理和发布。</p><p>使用<code>maven-archetype-plugin</code>，我们能够将一个已有的项目转化为<code>archetype project</code>。</p><p><img src="https://raw.githubusercontent.com/my-helloworld/template-springboot/master/doc/archetype-overview.png" alt="archetype"></p><p>通过生成的<code>archetype project</code>进行构建，就能生成<code>archetype jar</code>制品; </p><p>由于<code>archetype project</code>也是一个<code>maven</code>项目，因此和其他的<code>dependency jar</code>制品一样，<br>我们也可以通过<code>install</code>或<code>deploy</code>等指令在本地安装或者发布至远端。</p><h2 id="2-转化模板工程"><a href="#2-转化模板工程" class="headerlink" title="2. 转化模板工程"></a>2. 转化模板工程</h2><p>我们以一个简单的<code>springboot</code>模板项目为例, 可以在github上找到该<a href="https://github.com/my-helloworld/template-springboot" target="_blank" rel="noopener">项目地址</a></p><p>该模板结构如下</p><pre><code>-root  |-app         SpringBoot应用  |-checkstyle  项目风格检测工具  |-doc         项目文档与阅读资料  |-pom.xml     项目依赖配置与版本管理配置</code></pre><p>项目结构本身很简单，唯一定制的部分是构建过程要求做一些常见的静态检测，如<code>checkstyle</code>与<code>findbugs</code></p><p>接下来我们需要将这个项目转化为一个<code>archetype project</code>;</p><blockquote><p>指定<code>archetype</code>构建配置</p></blockquote><p>在项目的根目录下<code>pom.xml</code>声明配置:</p><pre><code class="xml">&lt;build&gt;    &lt;extensions&gt;        &lt;extension&gt;            &lt;groupId&gt;org.apache.maven.archetype&lt;/groupId&gt;            &lt;artifactId&gt;archetype-packaging&lt;/artifactId&gt;            &lt;version&gt;${ext.archetype.packaging.version}&lt;/version&gt;        &lt;/extension&gt;    &lt;/extensions&gt;&lt;/build&gt;</code></pre><blockquote><p>构建<code>archetype project</code></p></blockquote><p>在项目根目录下执行生成archetype</p><pre><code>mvn archetype:create-from-project</code></pre><p>该指令会在<code>${project.build.directory}/generated-sources/archetype</code>下生成模板工程<code>archetype project</code></p><pre><code>target/generated-sources/archetype|-- pom.xml`-- src    |-- main    |   `-- resources    |       |-- archetype-resources    |       |   |-- pom.xml    |       |   `-- src    |       |       |-- main    |       |       |   `-- java    |       |       |       `-- App.java    |       |       `-- test    |       |           `-- java    |       |               `-- AppTest.java    |       `-- META-INF    |           `-- maven    |               `-- archetype-metadata.xml    `-- test        `-- resources            `-- projects                `-- it-basic                    |-- archetype.properties                    `-- goal.txt</code></pre><h2 id="3-本地安装与使用"><a href="#3-本地安装与使用" class="headerlink" title="3 本地安装与使用"></a>3 本地安装与使用</h2><p>在第一步中，我们生成了<code>artifact project</code>，为了使用这个模板，我们需要在本地进行安装</p><blockquote><p>安装本地仓库</p></blockquote><p>和所有的源码发布流程一样，archetype生成了一个支持发布的pom配置, 因此只需要执行<code>install</code>即可</p><pre><code>cd target/generated-sources/archetypemvn install</code></pre><p>安装完毕后，能在本地的<code>~/.m2/repository/archetype-catalog.xml</code>中找到我们安装的<code>archetype</code>信息</p><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;archetype-catalog xsi:schemaLocation=&quot;http://maven.apache.org/plugins/maven-archetype-plugin/archetype-catalog/1.0.0     http://maven.apache.org/xsd/archetype-catalog-1.0.0.xsd&quot;    xmlns=&quot;http://maven.apache.org/plugins/maven-archetype-plugin/archetype-catalog/1.0.0&quot;    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;&gt;  &lt;archetypes&gt;    &lt;archetype&gt;      &lt;groupId&gt;com.chpengzh&lt;/groupId&gt;      &lt;artifactId&gt;template-springboot-archetype&lt;/artifactId&gt;      &lt;version&gt;latest&lt;/version&gt;      &lt;description&gt;template-springboot-archetype&lt;/description&gt;    &lt;/archetype&gt;  &lt;/archetypes&gt;&lt;/archetype-catalog&gt;</code></pre><blockquote><p>使用本地模板创建项目</p></blockquote><p>使用交互式命令行创建就能快速创建一个新的项目</p><pre><code>mvn archetype:generate -DarchetypeCatalog=local...Choose archetype:1: local -&gt; com.chpengzh:template-springboot-archetype (template-springboot-archetype)Choose a number or apply filter (format: [groupId:]artifactId, case sensitive contains): : 1  Define value for property &#39;groupId&#39;: com.alipay.sofaDefine value for property &#39;artifactId&#39;: a-new-project      Define value for property &#39;version&#39; 1.0-SNAPSHOT: : Define value for property &#39;package&#39; com.alipay.sofa: : Confirm properties configuration:groupId: com.alipay.sofaartifactId: a-new-projectversion: 1.0-SNAPSHOTpackage: com.alipay.sofa Y: : y...</code></pre><p>在shell场景，我们也可以使用预设环境变量的方式避免交互</p><pre><code>yes | mvn archetype:generate \    -DarchetypeCatalog=local \    -DarchetypeGroupId=com.chpengzh \    -DarchetypeArtifactId=template-springboot-archetype \    -DarchetypeVersion=latest \    -DgroupId=com.alipay.sofa \    -DartifactId=a-new-project \    -Dversion=1.0</code></pre><h2 id="4-发布与使用"><a href="#4-发布与使用" class="headerlink" title="4. 发布与使用"></a>4. 发布与使用</h2><p>和安装过程一致，要发布一个<code>archetype jar</code>的过程只需要执行<code>mvn deploy</code>即可；</p><p>关于发布的具体流程，请参阅<a href="https://maven.apache.org/plugins/maven-deploy-plugin/" target="_blank" rel="noopener">Deploy Plugin</a>，本章节不详细讲解;</p><blockquote><p>发布archetype</p></blockquote><p>修改<code>target/generated-sources/archetype/pom.xml</code></p><pre><code class="xml">&lt;distributionManagement&gt;    &lt;repository&gt;        &lt;id&gt;archetype-release&lt;/id&gt;        &lt;name&gt;Archetype Releases&lt;/name&gt;        &lt;url&gt;http://xxx&lt;/url&gt;    &lt;/repository&gt;    &lt;snapshotRepository&gt;        &lt;id&gt;archetype-snapshot&lt;/id&gt;        &lt;name&gt;Archetype Snapshots&lt;/name&gt;        &lt;url&gt;http://xxx&lt;/url&gt;    &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt;</code></pre><p>在<code>~/.m2/settings.xml</code>中添加授权信息(略)</p><p>发布</p><pre><code>cd target/generated-sources/archetypemvn deploy</code></pre><blockquote><p>使用发布的模板</p></blockquote><p>交互过程同本地创建</p><pre><code>mvn archetype:generate \    -DarchetypeCatalog=http://username:password@xxx/nexus/content/repositories/myapps/archetype-catalog.xml</code></pre><h2 id="阅读材料"><a href="#阅读材料" class="headerlink" title="阅读材料"></a>阅读材料</h2><ul><li><a href="https://maven.apache.org/plugins/maven-deploy-plugin/" target="_blank" rel="noopener">Apache Maven Project: maven-deploy-plugin</a></li><li><a href="https://maven.apache.org/guides/introduction/introduction-to-archetypes.html" target="_blank" rel="noopener">Apache Maven Project: introduction-to-archetypes</a></li><li><a href="https://xtuhcy.iteye.com/blog/1815061" target="_blank" rel="noopener">创建自定义的archetype</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Maven通用工程模板方案&quot;&gt;&lt;a href=&quot;#Maven通用工程模板方案&quot; class=&quot;headerlink&quot; title=&quot;Maven通用工程模板方案&quot;&gt;&lt;/a&gt;Maven通用工程模板方案&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;本文旨在介绍使用&lt;code
      
    
    </summary>
    
    
    
      <category term="projects" scheme="https://chpengzh.github.io/tags/projects/"/>
    
      <category term="maven" scheme="https://chpengzh.github.io/tags/maven/"/>
    
      <category term="spring-boot" scheme="https://chpengzh.github.io/tags/spring-boot/"/>
    
  </entry>
  
  <entry>
    <title>业务日志切面</title>
    <link href="https://chpengzh.github.io/%E4%B8%9A%E5%8A%A1%E6%97%A5%E5%BF%97%E5%88%87%E9%9D%A2/"/>
    <id>https://chpengzh.github.io/%E4%B8%9A%E5%8A%A1%E6%97%A5%E5%BF%97%E5%88%87%E9%9D%A2/</id>
    <published>2019-11-24T06:47:21.000Z</published>
    <updated>2019-11-24T09:12:18.208Z</updated>
    
    <content type="html"><![CDATA[<p>之前一个小朋友(目测年纪比我大)跑来询问了一个问题:</p><p>项目里面经常有各种各样的业务日志。这些日志通常情况下为一个文档，即带多个键值对属性，且有一个成功失败的标志。</p><p>至于日志的上报模式， 有的和业务在同一事务上下文，有的是独立于业务事务上下文，有的是异步日志记录(如ELK收集)。</p><blockquote><p>如果以Java为样例代码，形如:</p></blockquote><pre><code class="java">boolean isSuccess;ReportContext context;try {    Object result = businessProcess(); // 原始业务过程    //    // 在上下文中写如业务成功参数    //    context = doSomethingWithResult(result);     return result;} catch (Throwable err) {    //    // 在上下文中写入业务失败参数    //    context = doSomethingWithError(err);         throw err;} finally {    //    // 不管成功还是失败总是执行上报    //    reporter.report(context);                }</code></pre><p>其中<code>reporter</code>是一个抽象上报器，具体实现由具体业务方来制定。</p><p>这样的代码如果总是以这种格式，由业务方自己去编写，则业务线代码可读性会下降一个档次(事实上我同事写的很多代码都是这个尿性)。而要解决这个问题，针对这些不同的日志收集方式，我会选择封装一个统一的SDK供业务方使用。</p><h2 id="1-从线程调用栈出发"><a href="#1-从线程调用栈出发" class="headerlink" title="1. 从线程调用栈出发"></a>1. 从线程调用栈出发</h2><p>线程日志栈的解决方案主要思想参考了Spring的<code>Thread Scope</code>模式的Bean实现。</p><p>我们的业务代码时常是跑在业务线程池中。在每一个工作线程中，我们假设有一个日志栈。</p><ul><li><p>当进入到待记录的函数时, 我们创建一个<code>ReportContext</code>并压入线程栈</p></li><li><p>当业务执行过程中, 业务函数总是操作栈顶元素<code>ReportContext</code>(添加事件，修改属性等)</p></li><li><p>当退出带记录的函数是，我们总是取出栈顶元素并执行上报(<code>reporter::report</code>)</p></li></ul><p>样例代码参考如下:</p><pre><code class="java">public class DemoService {    private final ThreadLocal&lt;List&lt;OperationLog&gt;&gt; localRef = new InheritableThreadLocal&lt;&gt;();    private final OperationLog log = getAutowiredDelegate(); // Thread scope autowired delegate     public void doSomething() {        //        // Be designed as aspect        // ↓ ↓ ↓ ↓        push();        // ↑ ↑ ↑ ↑        try {            // Business function here            log.set(&quot;someRuntimeKey&quot;, &quot;someRuntimeValue&quot;);        } finally{            // ↓ ↓ ↓ ↓            OperationLog top = pop();            reportAsync(log);            // ↑ ↑ ↑ ↑            // Be designed as aspect            //        }    }    private OperationLog getAutowiredDelegate() {        //        // A proxy delegate by thread local reference        //    }}</code></pre><h2 id="2-一个实现样例"><a href="#2-一个实现样例" class="headerlink" title="2. 一个实现样例"></a>2. 一个实现样例</h2><p>日志切面的实现参考<code>OperationLogAspect</code></p><p>Demo中定义了一个被日志监管的业务函数</p><pre><code class="java">@Componentpublic static class TestRunner {    private static final Logger LOGGER = LoggerFactory.getLogger(TestRunner.class);    @Autowired    private OperationLog log;    @Operation(        type = &quot;runner-type&quot;,        tags = {&quot;demo&quot;, &quot;run&quot;},        desc = &quot;测试用例&quot;    )    public void run() {        int businessId = COUNT.getAndIncrement();        try {            LOGGER.info(&quot;业务{}.1&quot;, businessId);            log.getAnnotations().add(&quot;==&gt;1&quot;);            LOGGER.info(&quot;业务{}.2&quot;, businessId);            log.getAnnotations().add(&quot;==&gt;2&quot;);            if (Objects.equals(&quot;a&quot;, new String(&quot;a&quot;.getBytes()))) {                throw new RuntimeException(&quot;业务&quot; + businessId + &quot;.啊我死了!&quot;);            }        } catch (RuntimeException err) {            LOGGER.info(&quot;业务&quot; + businessId + &quot;.啊我死了!&quot;);            log.getAnnotations().add(err.getMessage());            throw err;        }    }}</code></pre><p>在线程池中运行，其结果如下</p><pre><code>2019-04-26 22:39:16 [pool-1-thread-3] 业务0.12019-04-26 22:39:16 [pool-1-thread-2] 业务1.12019-04-26 22:39:16 [pool-1-thread-1] 业务2.12019-04-26 22:39:16 [pool-1-thread-2] 业务1.22019-04-26 22:39:16 [pool-1-thread-3] 业务0.22019-04-26 22:39:16 [pool-1-thread-1] 业务2.22019-04-26 22:39:16 [pool-1-thread-3] 业务0.啊我死了!2019-04-26 22:39:16 [pool-1-thread-1] 业务2.啊我死了!2019-04-26 22:39:16 [pool-1-thread-2] 业务1.啊我死了!2019-04-26 22:39:16 [pool-1-thread-2] OperationLog{uuid=&#39;a279a6ac-7e36-4a5e-863d-266bba53b57b&#39;, level=common.operationLog.info, tags=[demo, run], annotations=[==&gt;1, ==&gt;2, 业务1.啊我死了!], timestamp=&#39;2019-04-26T22:39:16&#39;, localIp=&#39;192.168.53.58&#39;, success=false}2019-04-26 22:39:16 [pool-1-thread-1] OperationLog{uuid=&#39;6c5e689f-a4af-40c9-8873-53d504c782dc&#39;, level=common.operationLog.info, tags=[demo, run], annotations=[==&gt;1, ==&gt;2, 业务2.啊我死了!], timestamp=&#39;2019-04-26T22:39:16&#39;, localIp=&#39;192.168.53.58&#39;, success=false}2019-04-26 22:39:16 [pool-1-thread-3] OperationLog{uuid=&#39;5d9c6552-fe37-44c6-b95c-64664d0af2a5&#39;, level=common.operationLog.info, tags=[demo, run], annotations=[==&gt;1, ==&gt;2, 业务0.啊我死了!], timestamp=&#39;2019-04-26T22:39:16&#39;, localIp=&#39;192.168.53.58&#39;, success=false}2019-04-26 22:39:16 [pool-1-thread-3] 业务3.12019-04-26 22:39:16 [pool-1-thread-1] 业务4.12019-04-26 22:39:16 [pool-1-thread-3] 业务3.22019-04-26 22:39:16 [pool-1-thread-1] 业务4.22019-04-26 22:39:16 [pool-1-thread-3] 业务3.啊我死了!2019-04-26 22:39:16 [pool-1-thread-1] 业务4.啊我死了!2019-04-26 22:39:16 [pool-1-thread-3] OperationLog{uuid=&#39;03890d8b-efa3-4913-ac54-97c6f97c6cb9&#39;, level=common.operationLog.info, tags=[demo, run], annotations=[==&gt;1, ==&gt;2, 业务3.啊我死了!], timestamp=&#39;2019-04-26T22:39:16&#39;, localIp=&#39;192.168.53.58&#39;, success=false}2019-04-26 22:39:16 [pool-1-thread-1] OperationLog{uuid=&#39;652df431-c9ea-4a2a-b4f8-26c2689fa96b&#39;, level=common.operationLog.info, tags=[demo, run], annotations=[==&gt;1, ==&gt;2, 业务4.啊我死了!], timestamp=&#39;2019-04-26T22:39:16&#39;, localIp=&#39;192.168.53.58&#39;, success=false}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;之前一个小朋友(目测年纪比我大)跑来询问了一个问题:&lt;/p&gt;
&lt;p&gt;项目里面经常有各种各样的业务日志。这些日志通常情况下为一个文档，即带多个键值对属性，且有一个成功失败的标志。&lt;/p&gt;
&lt;p&gt;至于日志的上报模式， 有的和业务在同一事务上下文，有的是独立于业务事务上下文，有的
      
    
    </summary>
    
    
    
      <category term="java" scheme="https://chpengzh.github.io/tags/java/"/>
    
      <category term="projects" scheme="https://chpengzh.github.io/tags/projects/"/>
    
      <category term="aspectj" scheme="https://chpengzh.github.io/tags/aspectj/"/>
    
  </entry>
  
  <entry>
    <title>slf4j-api的源码解析与一个简单实现</title>
    <link href="https://chpengzh.github.io/SLF4J-API%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/"/>
    <id>https://chpengzh.github.io/SLF4J-API%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8E%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/</id>
    <published>2019-11-24T02:18:04.000Z</published>
    <updated>2019-11-24T02:52:36.718Z</updated>
    
    <content type="html"><![CDATA[<p>最近的工作里有好几个同事向我问起了<code>slf4j</code>的一些配置和使用问题。<br>本着问题需要被从根本解决的原则，我决定写一个样例项目来解释一下<code>slf4j-api</code>的一些接口问题，以及<code>log4j</code>对其的实现原理。</p><p>项目地址为 <a href="https://github.com/my-helloworld" target="_blank" rel="noopener">https://github.com/my-helloworld</a></p><p>本项目就是一个<code>slf4j-api</code>简单的异步日志实现，原理参考<code>slf4j-log4j12</code>。代码精简易懂，方便初学者了解<code>slf4j-log4j</code>的一些实现细节。</p><h2 id="1-关于-slf4j"><a href="#1-关于-slf4j" class="headerlink" title="1. 关于 slf4j"></a>1. 关于 slf4j</h2><p><a href="https://github.com/qos-ch/slf4j" target="_blank" rel="noopener">简单日志门面(Simple Logging Facade for java, SLF4J)</a>为各种日志框架提供了统一的接口封装，<br>包括<code>java.util.logging</code>,<code>logback</code>以及<code>Log4j</code>等，<br>使得最终用户能够在部署的时候灵活配置自己希望的Loging APIs实现。</p><p>在应用开发中，需要统一按照SLF4J的API进行开发，在部署时，选择不同的日志系统包加入到JAVA CLASSPATH中，<br>即可自动转换到不同的日志框架上。SLF4J隐藏了具体的转换、适配细节，将应用和具体日志框架解耦开来，<br>如果在类路径中没有发现绑定的日志实现，SLF4J默认使用NOP实现。</p><p>简言之，<code>slf4j-api</code>提供了一套标准的实现推展接口。<br>抽离日志接口API有利于解决日志实现的依赖问题, 任何一个模块只要引入 <code>slf4j-api</code> 而不需要关心实现。<br>而在构建应用入口的时候，在编译(或部署)时可以根据不同应用场景去引入不同的实现。</p><p>而针对不同实现，可以添加一些额外的配置(如<code>kafka broker server</code>、<code>email</code>等特殊实现所依赖的参数)。<br>这是典型的用插件化开发实现切片编程的思想。</p><p>由于<code>slf4j</code>影响广泛，几乎所有的近代<code>JEE</code>项目均采用这个接口标准进行接口拓展。</p><h2 id="2-从-slf4j-api-开始"><a href="#2-从-slf4j-api-开始" class="headerlink" title="2. 从 slf4j-api 开始"></a>2. 从 slf4j-api 开始</h2><p>我们在使用<code>slf4j</code>的时候会创建一个<code>Logger</code>对象，这个创建过程通常是</p><pre><code class="java">org.slf4j.Logger LOGGER = LoggerFactory.getLogger(&quot;some-logger-name&quot;);</code></pre><p>因此我们分析该方法, 能定位到其实现的绑定方法<code>LoggerFactory#getILoggerFactory()</code></p><pre><code class="java">public static ILoggerFactory getILoggerFactory() {    if (INITIALIZATION_STATE == UNINITIALIZED) {        synchronized (LoggerFactory.class) {            if (INITIALIZATION_STATE == UNINITIALIZED) {                INITIALIZATION_STATE = ONGOING_INITIALIZATION;                performInitialization();            }        }    }    switch (INITIALIZATION_STATE) {    case SUCCESSFUL_INITIALIZATION:        return StaticLoggerBinder.getSingleton().getLoggerFactory();    case NOP_FALLBACK_INITIALIZATION:        return NOP_FALLBACK_FACTORY;    case FAILED_INITIALIZATION:        throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG);    case ONGOING_INITIALIZATION:        // support re-entrant behavior.        // See also http://jira.qos.ch/browse/SLF4J-97        return SUBST_FACTORY;    }    throw new IllegalStateException(&quot;Unreachable code&quot;);}</code></pre><p>此方法中通过符号引用<code>org.slf4j.impl.StaticLoggerBinder.getSingleton().getLoggerFactory();</code>获取了一个<code>ILoggerFactory</code>对象。<br>而正如我们所求的，<code>ILoggerFactory</code> 正好就是需要我们实现的<code>Logger</code>工厂接口</p><pre><code class="java">public interface ILoggerFactory {    public Logger getLogger(String name);}</code></pre><p>前面之所以称符号引用，因为<code>slf4j-api</code>中并没有<code>StaticLoggerBinder</code>这个类。</p><p>参考<code>slf4j</code>文档，<code>slf4j-api</code> 需要我们实现一个类 <code>org.slf4j.impl.StaticLoggerBinder</code>, 同时这个类需要具有如下特征:</p><ul><li><p>获取Binder单例的静态方法 <code>public static StaticLoggerBinder getSingleton()</code></p></li><li><p>实现接口<code>ILoggerFactoryBinder</code></p></li></ul><pre><code class="java">public interface LoggerFactoryBinder {    public ILoggerFactory getLoggerFactory();    public String getLoggerFactoryClassStr();}</code></pre><h2 id="3-同步日志与异步日志"><a href="#3-同步日志与异步日志" class="headerlink" title="3. 同步日志与异步日志"></a>3. 同步日志与异步日志</h2><p>日志的本意就是将一些半结构化数据落盘，为未来的危险预警，灾难恢复以及数据分析等业务场景提供数据源。</p><p>常见的输出策略有</p><ul><li>进程标准输出(std_out/std_err)</li><li>持久化本地(或HDFS)文件</li><li>作为消息队列生产者(如:ELK框架)</li></ul><p>对此我们着重分析本地文件落盘的场景。</p><p>在讲文件写入之前，我们需要先了解下操作系统对文件读写提供了一个怎么样的IO模型。</p><h3 id="文件接口"><a href="#文件接口" class="headerlink" title="文件接口"></a>文件接口</h3><p>文件读写主要牵涉到了如下五个操作：打开、关闭、读、写、定位。在Linux系统中，提供了两套API，</p><p>一套是C标准API：fopen、fclose、fread、fwrite、fseek，</p><p>另一套则是POSIX定义的系统API：open、close、read、write、seek。</p><p>其中POSIX定义的API是系统API，而C标准API是基于系统API的封装，并且提供了额外的缓冲的功能。因此也可以把它们叫做缓冲I/O函数和非缓冲I/O函数。</p><p>相信各位java开发者对这些方法应该很熟了，确实java里面使用了<code>*Stream</code>类去包装这些文件系统直接提供的文件操作方法。</p><p>需要一提的是<code>FileOutputStream::write()</code>是一个native实现，且该操作不是一个线程安全的操作。</p><p>通常情况下要解决这个矛盾我们无非是通过加锁去实现, 当A,B两个线程竞争写文件f时，会分别执行</p><pre><code>[::lock()] -&gt; [A::write()] -&gt; [::unlock()] -&gt; [::lock()] -&gt; [B::write()] -&gt; [::unlock()] ...</code></pre><p>这样通过 <code>::lock()</code>/<code>::unlock()</code> 的方式竞争资源能保证并发环境下写入的线程安全性，这种写入方法我们称之为同步解决方案。</p><p>事实上这样的模型还能进一步进行抽象, 假定我们分配了一个独立线程加消息队<code>queue</code>列用于处理读写。<br>在该模型下，写操作会向该消息队列中添加写消息，而该线程只负责消费消息队列中的写事件。(参考<code>Android Framework</code> 中的<code>HandlerThread</code>)</p><pre><code>Thread A:    queue::add(A) # with lock    queue::add(B) # with lock    ...Thread B:    queue::poll() # fetch A and write, without lock    queue::poll() # fetch B and write, without lock    ...</code></pre><p>这个过程并没有消除竞争状态，但好处在于将写时的锁竞争抽象到了消息队列的<code>queue::add()</code>上执行，<br>而消费线程上执行的<code>queue::poll()</code>则不需要关心任何资源竞争的场景。</p><p>这种解决方案我们称之为异步解决方案</p><p>因此我们将高效写文件的核心资源竞争问题，递归到寻找一个高效的消息队列实现的问题上。</p><h3 id="JDK-内置队列"><a href="#JDK-内置队列" class="headerlink" title="JDK 内置队列"></a>JDK 内置队列</h3><p>Java的内置队列如下表所示。</p><table><thead><tr><th align="center">队列</th><th align="center">有界性</th><th align="center">锁</th><th align="center">数据结构</th></tr></thead><tbody><tr><td align="center">ArrayBlockingQueue</td><td align="center">bounded</td><td align="center">加锁</td><td align="center">arraylist</td></tr><tr><td align="center">LinkedBlockingQueue</td><td align="center">optionally-bounded</td><td align="center">加锁</td><td align="center">linkedlist</td></tr><tr><td align="center">ConcurrentLinkedQueue</td><td align="center">unbounded</td><td align="center">无锁</td><td align="center">linkedlist</td></tr><tr><td align="center">LinkedTransferQueue</td><td align="center">unbounded</td><td align="center">无锁</td><td align="center">linkedlist</td></tr><tr><td align="center">PriorityBlockingQueue</td><td align="center">unbounded</td><td align="center">加锁</td><td align="center">heap</td></tr><tr><td align="center">DelayQueue</td><td align="center">unbounded</td><td align="center">加锁</td><td align="center">heap</td></tr></tbody></table><p>队列的底层一般分成三种：数组、链表和堆。其中，堆一般情况下是为了实现带有优先级特性的队列，暂且不考虑。</p><p>我们就从数组和链表两种数据结构来看，基于数组线程安全的队列，<br>比较典型的是<code>ArrayBlockingQueue</code>，它主要通过加锁的方式来保证线程安全；<br>基于链表的线程安全队列分成<code>LinkedBlockingQueue</code>和<code>ConcurrentLinkedQueue</code>两大类，前者也通过锁的方式来实现线程安全，<br>而后者以及上面表格中的<code>LinkedTransferQueue</code>都是通过原子变量compare and swap（以下简称“CAS”）这种不加锁的方式来实现的。</p><p>通过不加锁的方式实现的队列都是无界的（无法保证队列的长度在确定的范围内）；<br>而加锁的方式，可以实现有界队列。在稳定性要求特别高的系统中，为了防止生产者速度过快，导致内存溢出，只能选择有界队列；<br>同时，为了减少Java的垃圾回收对系统性能的影响，会尽量选择array/heap格式的数据结构。<br>这样筛选下来，符合条件的队列就只有<code>ArrayBlockingQueue</code>。</p><p>那么我们将目光聚焦在<code>java</code>内置的<code>ArrayBlockingQueue</code>上，其默认实现方案为基于非公平重入锁。</p><blockquote><p>ArrayBlockingQueue 的重入锁锁声明</p></blockquote><pre><code class="java">/** Main lock guarding all access */final ReentrantLock lock;public ArrayBlockingQueue(int capacity) {    this(capacity, false);}public ArrayBlockingQueue(int capacity, boolean fair) {    if (capacity &lt;= 0)        throw new IllegalArgumentException();    this.items = new Object[capacity];    lock = new ReentrantLock(fair);    notEmpty = lock.newCondition();    notFull =  lock.newCondition();}</code></pre><blockquote><p>添加与消费</p></blockquote><pre><code class="java">public boolean offer(E e) {    checkNotNull(e);    final ReentrantLock lock = this.lock;    lock.lock();    try {        if (count == items.length)            return false;        else {            enqueue(e);            return true;        }    } finally {        lock.unlock();    }}public E poll() {    final ReentrantLock lock = this.lock;    lock.lock();    try {        return (count == 0) ? null : dequeue();    } finally {        lock.unlock();    }}</code></pre><h3 id="slf4j-log4j12-的-AsyncAppender-实现"><a href="#slf4j-log4j12-的-AsyncAppender-实现" class="headerlink" title="slf4j-log4j12 的 AsyncAppender 实现"></a>slf4j-log4j12 的 AsyncAppender 实现</h3><p>相信配置过log4j的同学应该对这个类还是比较熟悉的，但可能并没有仔细去阅读过其实现细节。</p><p><code>AsyncAppender</code>主要处理分发<code>log4j-api</code> 定义的<code>LoggingEvent</code>事件，并在一个<code>dispatcher</code>线程中执行日志写入</p><p>它使用了<code>ArrayList</code>作事件容器，并使用同步关键字<code>synchronized</code>对容器进行读写同步</p><blockquote><p>事件添加</p></blockquote><pre><code class="java">/** * Event buffer, also used as monitor to protect itself and * discardMap from simulatenous modifications. */private final List buffer = new ArrayList();public void append(final LoggingEvent event) {    //    //   if dispatcher thread has died then    //      append subsequent events synchronously    //   See bug 23021    if ((dispatcher == null) || !dispatcher.isAlive() || (bufferSize &lt;= 0)) {      synchronized (appenders) {        appenders.appendLoopOnAppenders(event);      }      return;    }    // Set the NDC and thread name for the calling thread as these    // LoggingEvent fields were not set at event creation time.    event.getNDC();    event.getThreadName();    // Get a copy of this thread&#39;s MDC.    event.getMDCCopy();    if (locationInfo) {      event.getLocationInformation();    }    event.getRenderedMessage();    event.getThrowableStrRep();    synchronized (buffer) {      while (true) {        int previousSize = buffer.size();        if (previousSize &lt; bufferSize) {          buffer.add(event);          //          //   if buffer had been empty          //       signal all threads waiting on buffer          //       to check their conditions.          //          if (previousSize == 0) {            buffer.notifyAll();          }          break;        }        //        //   Following code is only reachable if buffer is full        //        //        //   if blocking and thread is not already interrupted        //      and not the dispatcher then        //      wait for a buffer notification        boolean discard = true;        if (blocking                &amp;&amp; !Thread.interrupted()                &amp;&amp; Thread.currentThread() != dispatcher) {          try {            buffer.wait();            discard = false;          } catch (InterruptedException e) {            //            //  reset interrupt status so            //    calling code can see interrupt on            //    their next wait or sleep.            Thread.currentThread().interrupt();          }        }        //        //   if blocking is false or thread has been interrupted        //   add event to discard map.        //        if (discard) {          String loggerName = event.getLoggerName();          DiscardSummary summary = (DiscardSummary) discardMap.get(loggerName);          if (summary == null) {            summary = new DiscardSummary(event);            discardMap.put(loggerName, summary);          } else {            summary.add(event);          }          break;        }      }    }}</code></pre><blockquote><p>消费过程</p></blockquote><p>消费过程比较复杂，buffer容器被传递到了一个<code>Dispatcher</code>中(概念同<code>Android</code>中的<code>Handler</code>, <code>Disruptor</code>中的<code>EventHandler</code>)。<br>这个<code>Dispatcher</code>在异步线程中顺序消费事件，执行<code>epoll</code>循环。</p><p>每个周期都获取所有入队事件，并一次执行<code>appenders.appendLoopOnAppenders(events)</code>调用实际的消费逻辑</p><pre><code class="java">public void run() {  boolean isActive = true;  //  //   if interrupted (unlikely), end thread  //  try {    //    //   loop until the AsyncAppender is closed.    //    while (isActive) {      LoggingEvent[] events = null;      //      //   extract pending events while synchronized      //       on buffer      //      synchronized (buffer) {        int bufferSize = buffer.size();        isActive = !parent.closed;        while ((bufferSize == 0) &amp;&amp; isActive) {          buffer.wait();          bufferSize = buffer.size();          isActive = !parent.closed;        }        if (bufferSize &gt; 0) {          events = new LoggingEvent[bufferSize + discardMap.size()];          buffer.toArray(events);          //          //   add events due to buffer overflow          //          int index = bufferSize;          for (            Iterator iter = discardMap.values().iterator();              iter.hasNext();) {            events[index++] = ((DiscardSummary) iter.next()).createEvent();          }          //          //    clear buffer and discard map          //          buffer.clear();          discardMap.clear();          //          //    allow blocked appends to continue          buffer.notifyAll();        }      }      //      //   process events after lock on buffer is released.      //      if (events != null) {        for (int i = 0; i &lt; events.length; i++) {          synchronized (appenders) {            appenders.appendLoopOnAppenders(events[i]);          }        }      }    }  } catch (InterruptedException ex) {    Thread.currentThread().interrupt();  }}</code></pre><p>相比<code>ArrayBlockingQueue</code>实现，使用内置同步关键字的该实现更轻量级。<br>由于<code>ArrayBlockingQueue</code>默认使用非公平模式(java 的<code>synchronized</code>也没有保证公平行为)，甚至行为上二者行为上都是类似的。<br>唯一的区别可能就在于竞争时，线程状态是 <code>WAITING/TIMED_WAITING</code> 还是 <code>BLOCKING</code> 的区别。</p><h3 id="无锁消息队列-disruptor"><a href="#无锁消息队列-disruptor" class="headerlink" title="无锁消息队列 disruptor"></a>无锁消息队列 disruptor</h3><p>无锁消息队列 disruptor 原理参考美团的一篇博客<a href="https://tech.meituan.com/disruptor.html" target="_blank" rel="noopener">高性能队列——Disruptor</a>，本篇不做重复赘述。</p><h2 id="4-基于-disruptor-的异步日志实现"><a href="#4-基于-disruptor-的异步日志实现" class="headerlink" title="4. 基于 disruptor 的异步日志实现"></a>4. 基于 disruptor 的异步日志实现</h2><p>本<code>demo</code>项目目的在于实现一个<code>DemoAsyncLogger</code>实现对接<code>slf4j</code>，假设我们的日志事件定义如下:</p><pre><code class="java">public class LogEvent {    public Level level;    /**     * 这里让框架日志生成     */    public Supplier&lt;String&gt; msgSupplier;}</code></pre><blockquote><p>实现日志工厂</p></blockquote><p>日志工厂中需要读取配置文件，<code>slf4j-api</code> 中提供了一套解析配置的工具类，本文不对配置进行深入讨论，仅介绍一下<code>disruptor</code>的使用</p><pre><code class="java">/** * Logger的单例工厂，读取日志系统配置，并对日志落盘行为进行统一管理 */public enum DemoAsyncLoggerFactory implements ILoggerFactory {    /**     * 工厂单例     */    INSTANCE;    /**     * 异步落盘线程的执行队列，使用了无锁内存队列进行日志事件的管理     */    private final Disruptor&lt;LogEvent&gt; disruptor;    /**     * 日志等级，实际的项目中会通过配置管理来约束这个level, 可以设置为进程参数或是其他配置管理策略     */    private final Level level = Level.TRACE;    /**     * 创建一个日志工厂单例，该工厂将统一     */    DemoAsyncLoggerFactory() {        try {            // 这里为一个DEMO, 正式实现中会定义完整读取配置的方式            String file = String.format(&quot;/tmp/%s.log&quot;, UUID.randomUUID().toString());            //初始化 disruptor 进程            disruptor = new Disruptor&lt;&gt;(LogEvent::new, 1024, new LogThreadFactory(file));            disruptor.handleEventsWith(new LogEventHandler(                    new PrintWriter(new OutputStreamWriter(new FileOutputStream(file)))));            disruptor.start();        } catch (FileNotFoundException e) {            throw new RuntimeException(e);        }    }    /**     * 获取 Logger 实例(Logger工厂方法)     *     * @param name 日志名称     * @return Logger 实例     */    @Override    public Logger getLogger(String name) {        return new DemoAsyncLogger(name, disruptor);    }}</code></pre><blockquote><p>消息队列写入</p></blockquote><pre><code class="java">public class DemoAsyncLogger implements Logger {    //Override methods, ...    private void asyncLog(Level level, String msg, Throwable err) {        if (msg == null &amp;&amp; err == null) {            throw new IllegalArgumentException(&quot;both message and error are null&quot;);        }        StringBuilder msgBuilder = new StringBuilder();        if (msg != null) {            msgBuilder.append(msg).append(&quot;\n&quot;);        }        if (err != null) {            msgBuilder.append(err.toString());            for (StackTraceElement stackTrace : err.getStackTrace()) {                msgBuilder.append(stackTrace).append(&quot;\n&quot;);            }        }        msgBuilder.setLength(msgBuilder.length() - 1);        asyncLog(level, msgBuilder.toString());    }    /**     * 实际调用的事件的入队方法     */    private void asyncLog(Level level, String msg) {        long sequence = disruptor.getRingBuffer().next();        try {            LogEvent event = disruptor.getRingBuffer().get(sequence);            event.setLevel(level);            event.setMsgSupplier(() -&gt; String.format(&quot;%s\t%s&quot;, name, msg));        } finally {            disruptor.getRingBuffer().publish(sequence);        }    }}</code></pre><blockquote><p>消息队列的消费</p></blockquote><p>在工厂方法中我们看到了<code>Disruptor</code>在创建之后设置了一个handler用于在<code>Disruptor</code>工作线程中处理事件</p><pre><code class="java">public class LogEventHandler implements EventHandler&lt;LogEvent&gt; {    private final PrintWriter printer;    public LogEventHandler(PrintWriter printer) {        this.printer = printer;    }    /**     * 此函数会在`Disrtuptor`线程中调用, 因此在这里执行文件读写     */    @Override    public void onEvent(LogEvent event, long sequence, boolean endOfBatch) throws Exception {        System.out.printf(&quot;%d [%s] Thread %d-%s: %s%n&quot;,                sequence,                event.getLevel(),                Thread.currentThread().getId(),                Thread.currentThread().getName(),                event);        printer.printf(&quot;%d [%s] Thread %d-%s: %s%n&quot;,                sequence,                event.getLevel(),                Thread.currentThread().getId(),                Thread.currentThread().getName(),                event);        printer.flush();    }}</code></pre><blockquote><p>实现slf4j的接口绑定</p></blockquote><p>第二章我们提到，slf4j需要我们实现类<code>StaticLoggerBinder</code>单例</p><pre><code class="java">/** * slf4j 实现对接的接口类 */public enum StaticLoggerBinder implements LoggerFactoryBinder {    /**     * Binder 单例     */    INSTANCE;    /**     * Logger Factory name     */    private static final String LOGGER_FACTORY_NAME = DemoAsyncLogger.class.getName();    /**     * StaticLoggerBinder 单例, slf4j-api 将调用该方法进行实现绑定     *     * @return StaticLoggerBinder实例     * @see LoggerFactory#bind()     */    public static StaticLoggerBinder getSingleton() {        return INSTANCE;    }    @Override    public ILoggerFactory getLoggerFactory() {        return DemoAsyncLoggerFactory.INSTANCE;    }    @Override    public String getLoggerFactoryClassStr() {        return LOGGER_FACTORY_NAME;    }}</code></pre><blockquote><p>调用测试</p></blockquote><pre><code class="java">public class Main {    private static final Logger LOG = LoggerFactory.getLogger(Main.class);    public static void main(String... args) throws InterruptedException {        LOG.trace(&quot;test&quot;);        LOG.debug(&quot;test1&quot;);        LOG.info(&quot;test2&quot;);        Thread.sleep(100);        LOG.warn(&quot;test2&quot;);        LOG.error(&quot;test3&quot;);    }}//--------------------------------//--------------------------------disruptor thread is started, output log file: /tmp/134fd4e4-7ecb-4b68-86cb-b4e8c1e335c5.log0 [TRACE] Thread 12-demo-log: com.chpengzh.slf4j.Main    test1 [DEBUG] Thread 12-demo-log: com.chpengzh.slf4j.Main    test12 [INFO] Thread 12-demo-log: com.chpengzh.slf4j.Main    test23 [WARN] Thread 12-demo-log: com.chpengzh.slf4j.Main    test24 [ERROR] Thread 12-demo-log: com.chpengzh.slf4j.Main    test3</code></pre><h2 id="5-小结与参考链接"><a href="#5-小结与参考链接" class="headerlink" title="5 小结与参考链接"></a>5 小结与参考链接</h2><p>本文主要是研究了日志框架<code>sfl4j</code>的接口实现层对接策略，以及异步日志框架的一般实现思路。<br>在一些本地进程锁竞争较为激烈的场景，使用无锁消息队列的解决方案成为了一些较为简单的解决方案。<br>同时，以<code>slf4j</code>为首的插件化思想也是值得参考的一种架构层设计模式。</p><ul><li><a href="http://www.luohw.com/notes/slf4j-log4j-%E6%97%A5%E5%BF%97%E6%A1%86%E6%9E%B6%E4%BC%97.html" target="_blank" rel="noopener">SLF4J、Log4j、日志框架众</a></li><li><a href="https://item.jd.com/11469694.html" target="_blank" rel="noopener">《UNIX环境高级编程》</a></li><li><a href="https://tech.meituan.com/disruptor.html" target="_blank" rel="noopener">高性能队列——Disruptor</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近的工作里有好几个同事向我问起了&lt;code&gt;slf4j&lt;/code&gt;的一些配置和使用问题。&lt;br&gt;本着问题需要被从根本解决的原则，我决定写一个样例项目来解释一下&lt;code&gt;slf4j-api&lt;/code&gt;的一些接口问题，以及&lt;code&gt;log4j&lt;/code&gt;对其的实现原
      
    
    </summary>
    
    
    
      <category term="java" scheme="https://chpengzh.github.io/tags/java/"/>
    
      <category term="projects" scheme="https://chpengzh.github.io/tags/projects/"/>
    
      <category term="slf4j" scheme="https://chpengzh.github.io/tags/slf4j/"/>
    
  </entry>
  
</feed>
